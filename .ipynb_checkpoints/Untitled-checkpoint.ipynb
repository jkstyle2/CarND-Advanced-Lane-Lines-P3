{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Find all images matching a pattern \n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "object_points, img_points = [], []\n",
    "\n",
    "objp = np.zeros((9 * 5, 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:9, 0:5].T.reshape(-1, 2)\n",
    "\n",
    "for filename in images:\n",
    "    # read in image \n",
    "    img = cv2.imread(filename)\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # find the corners \n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9, 5), None)\n",
    "    \n",
    "    if ret == True:\n",
    "        img_points.append(corners)\n",
    "        object_points.append(objp)\n",
    "\n",
    "        cv2.drawChessboardCorners(img, (9, 5), corners, ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=[25, 25])\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(object_points, img_points, (1280, 720), None, None)\n",
    "dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "figure.add_subplot(1, 2, 1)\n",
    "plt.imshow(img)\n",
    "plt.title('Original Distorted')\n",
    "figure.add_subplot(1, 2, 2)\n",
    "plt.imshow(dst)\n",
    "plt.title('Undistorted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Calibration:\n",
    "    def __init__(self, mtx, dist):\n",
    "        self.__mtx  = mtx\n",
    "        self.__dist = dist\n",
    "\n",
    "    @property\n",
    "    def mtx(self):\n",
    "        return self.__mtx\n",
    "\n",
    "    @property\n",
    "    def dist(self):\n",
    "        return self.__dist\n",
    "\n",
    "\n",
    "class Pipeline:\n",
    "    def __init__(self, calibration):\n",
    "        self.calibration = calibration\n",
    "\n",
    "    # Helper Utilities\n",
    "    def hls(self, image, threshold=[170, 255]):\n",
    "        \"\"\"Extract S channel from image\"\"\"\n",
    "        hls_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "        s_channel = hls_image[:,:, 2]\n",
    "\n",
    "        binary = np.zeros_like(s_channel)\n",
    "        binary[(s_channel >= threshold[0]) & (s_channel <= threshold[1])] = 1\n",
    "\n",
    "        return binary\n",
    "\n",
    "    def undistort(self, image):\n",
    "        \"\"\"Undistort the image given the distortion matrix and destination points\"\"\"\n",
    "        return cv2.undistort(image,\n",
    "            self.calibration.mtx,\n",
    "            self.calibration.dist, None,\n",
    "            self.calibration.mtx)\n",
    "\n",
    "    def lab(self, image, threshold=[150,255]):\n",
    "        lab_color_space = cv2.cvtColor(image, cv2.COLOR_RGB2Lab)\n",
    "        b_channel = lab_color_space[:, :, 2]\n",
    "\n",
    "        binary = np.zeros_like(b_channel)\n",
    "        binary[((b_channel >= threshold[0]) & (b_channel <= threshold[1]))] = 1\n",
    "\n",
    "        return binary\n",
    "\n",
    "    def color_threshold(self, image):\n",
    "        \"\"\"Extract R and S channels from `image`.\"\"\"\n",
    "        b_channel_threshold = self.lab(image)\n",
    "        s_channel_threshold = self.hls(image)\n",
    "\n",
    "        color_composite = np.zeros_like(s_channel_threshold)\n",
    "        color_composite[((s_channel_threshold == 1) | (b_channel_threshold == 1))] = 1\n",
    "\n",
    "        return color_composite\n",
    "\n",
    "    def sobelize(self, image, kernel_size=9):\n",
    "        \"\"\"Helper function to calculate the Sobel in the X and Y directions\"\"\"\n",
    "        sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize = kernel_size)\n",
    "        sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize = kernel_size)\n",
    "\n",
    "        return sobel_x, sobel_y\n",
    "\n",
    "    def sobel_threshold(self, image, orientation='x', min_threshold=30, max_threshold=255):\n",
    "        \"\"\"Absolute Sobel threshold. Adapted from the lectures.\"\"\"\n",
    "        if orientation == 'x':\n",
    "            sobel, _ = self.sobelize(image)\n",
    "        else:\n",
    "            _, sobel = self.sobelize(image)\n",
    "\n",
    "        absolute_sobel = np.absolute(sobel)\n",
    "        scaled_sobel = np.uint8(np.multiply(255, absolute_sobel) / np.max(absolute_sobel))\n",
    "\n",
    "        binary = np.zeros_like(scaled_sobel)\n",
    "        binary[(scaled_sobel >= min_threshold) & (scaled_sobel <= max_threshold)] = 1\n",
    "\n",
    "        return binary\n",
    "\n",
    "    def magnitude_threshold(self, image, sobel_kernel_size=9, threshold=[40, 200]):\n",
    "        \"\"\"Adapted from the lectures\"\"\"\n",
    "\n",
    "        sobel_x, sobel_y = self.sobelize(image, kernel_size=sobel_kernel_size)\n",
    "\n",
    "        gradient_magnitude = np.sqrt(np.square(sobel_x) + np.square(sobel_y))\n",
    "        scaling_factor = np.divide(np.max(gradient_magnitude), 255)\n",
    "        scaled_gradient = np.divide(gradient_magnitude, scaling_factor).astype(np.uint8)\n",
    "\n",
    "        binary = np.zeros_like(scaled_gradient)\n",
    "        binary[(scaled_gradient >= threshold[0]) & (scaled_gradient <= threshold[1])] = 1\n",
    "\n",
    "        return binary\n",
    "\n",
    "    def directional_threshold(self, image, sobel_kernel_size=9, threshold=[0.6, 1.1]):\n",
    "        \"\"\"Adapted from the lectures\"\"\"\n",
    "\n",
    "        sobel_x, sobel_y = self.sobelize(image, kernel_size = sobel_kernel_size)\n",
    "\n",
    "        directional_gradient = np.arctan2(np.absolute(sobel_y), np.absolute(sobel_x))\n",
    "\n",
    "        binary =  np.zeros_like(directional_gradient)\n",
    "        binary[(directional_gradient >= threshold[0]) & (directional_gradient <= threshold[1])] = 1\n",
    "\n",
    "        return binary\n",
    "\n",
    "    def gradient_thresholds(self, image):\n",
    "        # Sobel Gradients\n",
    "        x_gradient = self.sobel_threshold(image, orientation='x', min_threshold=30, max_threshold=200)\n",
    "        y_gradient = self.sobel_threshold(image, orientation='y', min_threshold=30, max_threshold=200)\n",
    "\n",
    "        # Mag Gradient\n",
    "        magnitude_threshold = self.magnitude_threshold(image, threshold=[50, 255])\n",
    "        # Directional Gradient\n",
    "        directional_gradient = self.directional_threshold(image, threshold=[0.7, 1.3])\n",
    "\n",
    "        gradient_composite = np.zeros_like(directional_gradient)\n",
    "        gradient_composite[((x_gradient == 1 | (magnitude_threshold == 1)) & ((directional_gradient == 1) | (y_gradient == 1)))] = 1\n",
    "\n",
    "        return gradient_composite\n",
    "\n",
    "    def composite_threshold(self, gradient_threshold, color_threshold):\n",
    "        \"\"\"Combine Gradient and Color threholds\"\"\"\n",
    "        binary = np.zeros_like(gradient_threshold)\n",
    "        binary[(gradient_threshold == 1) | (color_threshold == 1)] = 1\n",
    "\n",
    "        return binary\n",
    "\n",
    "    def warp(self, image):\n",
    "        image_size = (image.shape[1], image.shape[0])\n",
    "        \n",
    "#         bottom_left = [220,720]\n",
    "#         bottom_right = [1110, 720]\n",
    "#         top_left = [570, 470]\n",
    "#         top_right = [722, 470]\n",
    "\n",
    "#         source = np.float32([bottom_left,bottom_right,top_right,top_left])\n",
    "\n",
    "#         bottom_left = [320,720]\n",
    "#         bottom_right = [920, 720]\n",
    "#         top_left = [320, 1]\n",
    "#         top_right = [920, 1]\n",
    "\n",
    "#         destination = np.float32([bottom_left,bottom_right,top_right,top_left])\n",
    "\n",
    "        source = np.float32(\n",
    "            [[500, 480],\n",
    "             [810, 482],\n",
    "             [1250, 720],\n",
    "             [40, 720]])\n",
    "\n",
    "        destination = np.float32(\n",
    "            [[0, 0],\n",
    "             [1200, 0],\n",
    "             [1200, 720],\n",
    "             [0, 720]])\n",
    "\n",
    "        matrix = cv2.getPerspectiveTransform(source, destination)\n",
    "        inverse_matrix = cv2.getPerspectiveTransform(destination, source)\n",
    "        warped_image = cv2.warpPerspective(image, matrix, image_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "        return warped_image, matrix, inverse_matrix\n",
    "\n",
    "    def find_lane(self, binary_warped, **kwargs):\n",
    "        \"\"\"Adapted from Udacity's lectures\"\"\"\n",
    "        histogram = np.sum(binary_warped[binary_warped.shape[0] // 2:,:], axis=0)\n",
    "        out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "        midpoint = np.int(histogram.shape[0] / 2)\n",
    "        leftx_base = np.argmax(histogram[:midpoint])\n",
    "        rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "        nwindows = 9\n",
    "        window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "        nonzero = binary_warped.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        leftx_current = leftx_base\n",
    "        rightx_current = rightx_base\n",
    "        margin = 100\n",
    "        minpix = 50\n",
    "        left_lane_inds = []\n",
    "        right_lane_inds = []\n",
    "        for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "            win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "            win_y_high = binary_warped.shape[0] - window*window_height\n",
    "            win_xleft_low = leftx_current - margin\n",
    "            win_xleft_high = leftx_current + margin\n",
    "            win_xright_low = rightx_current - margin\n",
    "            win_xright_high = rightx_current + margin\n",
    "\n",
    "            # Draw the windows on the visualization image\n",
    "            cv2.rectangle(out_img, (win_xleft_low,win_y_low), (win_xleft_high,win_y_high), (0,255,0), 2)\n",
    "            cv2.rectangle(out_img, (win_xright_low,win_y_low), (win_xright_high,win_y_high), (0,255,0), 2)\n",
    "\n",
    "            # Identify the nonzero pixels in x and y within the window\n",
    "            good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "            good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "\n",
    "            # Append these indices to the lists\n",
    "            left_lane_inds.append(good_left_inds)\n",
    "            right_lane_inds.append(good_right_inds)\n",
    "\n",
    "            if len(good_left_inds) > minpix:\n",
    "                leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "            if len(good_right_inds) > minpix:\n",
    "                rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "        # Concatenate the arrays of indices\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "        # Extract left and right line pixel positions\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds]\n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "        # Fit a second order polynomial to each\n",
    "#         print(lefty.shape, leftx.shape)\n",
    "#         print(righty.shape, rightx.shape)\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        if righty.shape == 0 or rightx.shape == 0:\n",
    "            return \n",
    "\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "\n",
    "        # Generate x and y values for plotting\n",
    "        ploty = np.linspace(0, img.shape[0]-1, img.shape[0] )\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "        return ploty, lefty, righty, leftx, rightx, left_fitx, right_fitx\n",
    "\n",
    "    def curvature_offset(self, ploty, lefty, righty, leftx, rightx, leftfitx, rightfitx):\n",
    "        image_width, image_height = 1280, 720\n",
    "        y_eval = np.max(ploty)\n",
    "\n",
    "        lane_pixel_width = np.multiply(image_width, 0.57)\n",
    "        meters_per_pixel_y = np.divide(23, image_height)\n",
    "        meters_per_pixel_x = np.divide(3.7, lane_pixel_width)\n",
    "\n",
    "        left_fit_cr = np.polyfit(lefty * meters_per_pixel_y, leftx * meters_per_pixel_x, deg=2)\n",
    "        right_fit_cr = np.polyfit(righty * meters_per_pixel_y, rightx * meters_per_pixel_x, deg=2)\n",
    "\n",
    "        # Adapted from Udacity lectures\n",
    "        radius_curvature_left = ((1 + (2 * left_fit_cr[0] * y_eval * meters_per_pixel_y + left_fit_cr[1]) ** 2) ** 1.5) / np.absolute(2 * left_fit_cr[0])\n",
    "        right_curverad = ((1 + (2 * right_fit_cr[0] * y_eval*meters_per_pixel_y + right_fit_cr[1]) ** 2) ** 1.5) / np.absolute(2 * right_fit_cr[0])\n",
    "        curvature_radius = np.mean([radius_curvature_left, right_curverad])\n",
    "        \n",
    "        lane_center = (rightfitx[719] + leftfitx[719])/2\n",
    "        xm_per_pix = 3.7 / 700 \n",
    "        center_offset_pixels = abs(image_width / 2 - lane_center)\n",
    "        center_offset_mtrs = xm_per_pix * center_offset_pixels\n",
    "\n",
    "#         car_center = (left_fitx[-1] + right_fitx[-1]) / 2\n",
    "#         image_center = image_width / 2\n",
    "#         vehicle_offset = (image_center - car_center) * (3.7/700)\n",
    "\n",
    "        return curvature_radius, center_offset_mtrs\n",
    "\n",
    "    def draw_lane(self, warped_image, undistorted_image, inverse_matrix, ploty,\n",
    "            left_fitx, right_fitx, curvature_radius, vehicle_offset):\n",
    "        \"\"\"Draw the lane onto the image and apply the text.\"\"\"\n",
    "        warp_zero = np.zeros_like(warped_image).astype(np.uint8)\n",
    "\n",
    "        color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "        image_size = (color_warp.shape[1], color_warp.shape[0])\n",
    "\n",
    "        left_points = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "        right_points = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "        left_and_right_points = np.hstack((left_points, right_points))\n",
    "\n",
    "        cv2.fillPoly(color_warp, np.int_([left_and_right_points]), (0,255, 0))\n",
    "        newwarp = cv2.warpPerspective(color_warp, inverse_matrix, image_size)\n",
    "        result = cv2.addWeighted(undistorted_image, 1, newwarp, 0.3, 0)\n",
    "\n",
    "        cv2.putText(result, 'Distance from center: {:.2f} m'.format(vehicle_offset), (100,80), fontFace = 16,\\\n",
    "                        fontScale = 2, color=(255,255,255), thickness = 4)\n",
    "\n",
    "        cv2.putText(result, 'Radius of Curvature {} m'.format(int(curvature_radius)), (120,140),\n",
    "                 fontFace = 16, fontScale = 2, color=(255,255,255), thickness = 4)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def run(self, image):\n",
    "        # Undisort the image\n",
    "        undistorted_image = self.undistort(image)\n",
    "        \n",
    "        gray = cv2.cvtColor(undistorted_image, cv2.COLOR_BGR2GRAY)\n",
    "        # Color thresholds\n",
    "        color_threshold = self.color_threshold(undistorted_image)\n",
    "\n",
    "        # Gradient threshold\n",
    "        gradient_threshold = self.gradient_thresholds(gray)\n",
    "\n",
    "        # Combine Gradient and Color thresholding\n",
    "#         combined_thresholds = self.composite_threshold(gradient_threshold, color)\n",
    "        combined_thresholds = self.composite_threshold(gradient_threshold, color_threshold)\n",
    "\n",
    "        # Warp the image\n",
    "        warped_image, _, inverse_matrix = self.warp(combined_thresholds)\n",
    "        \n",
    "        # Draw the lane and derive the curvature offeset\n",
    "        ploty, lefty, righty, leftx, rightx, left_fitx, right_fitx = self.find_lane(warped_image)\n",
    "\n",
    "        curvature_radius, car_offset = self.curvature_offset(ploty, lefty, righty, leftx, rightx, left_fitx, right_fitx)\n",
    "\n",
    "        output = self.draw_lane(warped_image, undistorted_image,\n",
    "            inverse_matrix, ploty, left_fitx, right_fitx, curvature_radius, car_offset)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(object_points, img_points, (1280, 720), None, None)\n",
    "\n",
    "calibration = Calibration(mtx=mtx, dist=dist)\n",
    "pipeline = Pipeline(calibration)\n",
    "\n",
    "test_images = glob.glob('test_images/test*.jpg')\n",
    "imgs = []\n",
    "for path in test_images:\n",
    "    image = cv2.imread(path)\n",
    "    imgs.append({ 'image': image, 'path': path })\n",
    "    \n",
    "test_images = imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=[25, 25])\n",
    "\n",
    "image = cv2.imread('test_images/test6.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Use distortion matrix to undistort image\n",
    "dst = pipeline.undistort(image)\n",
    "    \n",
    "figure.add_subplot(1, 2, 1)\n",
    "plt.imshow(image)\n",
    "plt.title('Original Distorted', fontsize=20)\n",
    "figure.add_subplot(1, 2, 2)\n",
    "plt.imshow(dst)\n",
    "plt.title('Undistorted', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=[25, 25])\n",
    "\n",
    "image = cv2.imread('test_images/test6.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "color = pipeline.color_threshold(image)\n",
    "gradient = pipeline.gradient_thresholds(gray)\n",
    "\n",
    "out = pipeline.composite_threshold(gradient, color)\n",
    "yo  = pipeline.run(image)\n",
    "plt.title('Combined Color + Gradient Thresholds', fontsize=20)\n",
    "plt.imshow(yo, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
